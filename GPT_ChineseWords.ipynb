{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Constants\n",
    "from  openai import OpenAI\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import gspread\n",
    "import gspread_dataframe as gd\n",
    "import gspread_formatting as gf\n",
    "from gspread_formatting import cellFormat, color, textFormat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample OpenAI Prompt Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = Constants.API_KEY_OPENAI,\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4o-mini\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Google Sheet API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Words Num Rows: 99\n",
      "Sheet Words Num Columns: 8\n"
     ]
    }
   ],
   "source": [
    "# No need to provide path for service account.  Json file is in the default directory for gspread at %APPDATA%/gspread/service_account.json\n",
    "sa = gspread.service_account()\n",
    "sh = sa.open(\"New Chinese Words\")\n",
    "\n",
    "sheet_name = \"Words\"\n",
    "wks2 = sh.worksheet(sheet_name)\n",
    "print(f'Sheet {sheet_name} Num Rows: {wks2.row_count}')\n",
    "print(f'Sheet {sheet_name} Num Columns: {wks2.col_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Type</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence Pinyin</th>\n",
       "      <th>Sentence Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>大概</td>\n",
       "      <td>da4 gai4</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>Approximately</td>\n",
       "      <td>他大概已经出发了</td>\n",
       "      <td>Tā dàgài yǐjīng chūfā le.</td>\n",
       "      <td>He probably already left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>被</td>\n",
       "      <td>bei4</td>\n",
       "      <td>Particle</td>\n",
       "      <td>Particle word to turn into passive voice.  (.i...</td>\n",
       "      <td>甜甜圈被吃掉了</td>\n",
       "      <td>tian2 tian2 quan1 bei4 chi1 diao4 le</td>\n",
       "      <td>The donut was eaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>往前</td>\n",
       "      <td>wang3 qian2</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>Go forward</td>\n",
       "      <td>往前走</td>\n",
       "      <td>wang3 qian2 zou3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>觉得</td>\n",
       "      <td>jue2 de</td>\n",
       "      <td>Verb</td>\n",
       "      <td>Think</td>\n",
       "      <td>你觉得她怎么样</td>\n",
       "      <td>ni3 jue2 de ta1 zen3 me yang</td>\n",
       "      <td>What do you think about her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>已经</td>\n",
       "      <td>yi3 jing1</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>Already</td>\n",
       "      <td>我已经吃过晚饭了</td>\n",
       "      <td>Wǒ yǐjīng chī guò wǎnfàn le.</td>\n",
       "      <td>I have already had dinner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 Word       Pinyin       Type  \\\n",
       "1   大概     da4 gai4  Adjective   \n",
       "2    被         bei4   Particle   \n",
       "3   往前  wang3 qian2  Adjective   \n",
       "4   觉得      jue2 de       Verb   \n",
       "5   已经    yi3 jing1     Adverb   \n",
       "\n",
       "0                                            Meaning  Sentence  \\\n",
       "1                                      Approximately  他大概已经出发了   \n",
       "2  Particle word to turn into passive voice.  (.i...   甜甜圈被吃掉了   \n",
       "3                                        Go forward        往前走   \n",
       "4                                              Think   你觉得她怎么样   \n",
       "5                                            Already  我已经吃过晚饭了   \n",
       "\n",
       "0                       Sentence Pinyin             Sentence Meaning  \n",
       "1             Tā dàgài yǐjīng chūfā le.     He probably already left  \n",
       "2  tian2 tian2 quan1 bei4 chi1 diao4 le          The donut was eaten  \n",
       "3                      wang3 qian2 zou3                               \n",
       "4          ni3 jue2 de ta1 zen3 me yang  What do you think about her  \n",
       "5          Wǒ yǐjīng chī guò wǎnfàn le.    I have already had dinner  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data = pd.DataFrame(wks2.get_all_values())\n",
    "current_data.columns = current_data.iloc[0]\n",
    "current_data = current_data.iloc[1:]\n",
    "current_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.translation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.7\n",
    "overwrite_mode = False\n",
    "\n",
    "dict_path = \"ChineseWords/ChineseWordList.csv\"\n",
    "dict_sheet_name = \"Tua_List\"\n",
    "gsheet_name = \"New Chinese Words\"\n",
    "\n",
    "\n",
    "df = load_dict(gsheet_mode=True, gsheet_name=gsheet_name, worksheet_name=dict_sheet_name)\n",
    "cat = df['Word Category'].drop_duplicates().sort_values().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = \"\"\"\n",
    "            空当, \n",
    "            见， \n",
    "            看\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_translation_pipeline(\n",
    "    word_list = word_list, \n",
    "    gsheet_name = gsheet_name, \n",
    "    worksheet_name = dict_sheet_name, \n",
    "    overwrite_mode = True,\n",
    "    translation_model = \"gpt-4o\", \n",
    "    rarity_model = \"gpt-4o-mini\",\n",
    "    temp = 0.7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongs\\Documents\\DS Work\\repo\\Pytorch LLM\\GPT4LanguageLearning\\main\\translation.py:233: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Pinyin Simplified</th>\n",
       "      <th>Type</th>\n",
       "      <th>Word Category</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence Pinyin</th>\n",
       "      <th>Sentence Meaning</th>\n",
       "      <th>Added Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>地图</td>\n",
       "      <td>dì tú</td>\n",
       "      <td>di4 tu2</td>\n",
       "      <td>Noun</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Map</td>\n",
       "      <td>我需要一张地图来找到那家餐厅。</td>\n",
       "      <td>Wǒ xūyào yī zhāng dìtú lái zhǎodào nà jiā cānt...</td>\n",
       "      <td>I need a map to find that restaurant.</td>\n",
       "      <td>2024-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>晚点</td>\n",
       "      <td>wǎn diǎn</td>\n",
       "      <td>wan3 dian3</td>\n",
       "      <td>Verb</td>\n",
       "      <td>Time</td>\n",
       "      <td>To be delayed; typically used for transportati...</td>\n",
       "      <td>飞机晚点了一个小时。</td>\n",
       "      <td>Fēijī wǎndiǎn le yī gè xiǎoshí.</td>\n",
       "      <td>The flight was delayed by an hour.</td>\n",
       "      <td>2024-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>起飞</td>\n",
       "      <td>qǐ fēi</td>\n",
       "      <td>qi3 fei1</td>\n",
       "      <td>Verb</td>\n",
       "      <td>Travel</td>\n",
       "      <td>To take off; used for airplanes.</td>\n",
       "      <td>飞机将在下午三点起飞。</td>\n",
       "      <td>Fēijī jiāng zài xiàwǔ sān diǎn qǐfēi.</td>\n",
       "      <td>The plane will take off at 3 PM.</td>\n",
       "      <td>2024-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>降落</td>\n",
       "      <td>jiàng luò</td>\n",
       "      <td>jiang4 luo4</td>\n",
       "      <td>Verb</td>\n",
       "      <td>Travel</td>\n",
       "      <td>To land; used for airplanes.</td>\n",
       "      <td>飞机已经安全降落在机场。</td>\n",
       "      <td>Fēijī yǐjīng ānquán jiàngluò zài jīchǎng.</td>\n",
       "      <td>The plane has landed safely at the airport.</td>\n",
       "      <td>2024-10-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word     Pinyin Pinyin Simplified  Type Word Category  \\\n",
       "1   地图      dì tú           di4 tu2  Noun     Geography   \n",
       "2   晚点   wǎn diǎn        wan3 dian3  Verb          Time   \n",
       "3   起飞     qǐ fēi          qi3 fei1  Verb        Travel   \n",
       "4   降落  jiàng luò       jiang4 luo4  Verb        Travel   \n",
       "\n",
       "                                             Meaning         Sentence  \\\n",
       "1                                                Map  我需要一张地图来找到那家餐厅。   \n",
       "2  To be delayed; typically used for transportati...       飞机晚点了一个小时。   \n",
       "3                   To take off; used for airplanes.      飞机将在下午三点起飞。   \n",
       "4                       To land; used for airplanes.     飞机已经安全降落在机场。   \n",
       "\n",
       "                                     Sentence Pinyin  \\\n",
       "1  Wǒ xūyào yī zhāng dìtú lái zhǎodào nà jiā cānt...   \n",
       "2                    Fēijī wǎndiǎn le yī gè xiǎoshí.   \n",
       "3              Fēijī jiāng zài xiàwǔ sān diǎn qǐfēi.   \n",
       "4          Fēijī yǐjīng ānquán jiàngluò zài jīchǎng.   \n",
       "\n",
       "                              Sentence Meaning  Added Date  \n",
       "1        I need a map to find that restaurant.  2024-10-23  \n",
       "2           The flight was delayed by an hour.  2024-10-23  \n",
       "3             The plane will take off at 3 PM.  2024-10-23  \n",
       "4  The plane has landed safely at the airport.  2024-10-23  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_response_translation = (\n",
    "    get_completion(\n",
    "        prompt=get_prompt_for_chinese_translation(word_list), model=\"gpt-4o-mini\" , temperature=temp))\n",
    "content = sample_response_translation.choices[0].message.content\n",
    "\n",
    "newwords_df = (\n",
    "    parse_translation_response(\n",
    "        content,\n",
    "        ffill_cols = ['Word', 'Pinyin', 'Pinyin Simplified', 'Type'],\n",
    "        date_col = ['Added Date']\n",
    "        )\n",
    "      )\n",
    "\n",
    "new_words = newwords_df['Word'].drop_duplicates().values\n",
    "newwords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongs\\Documents\\DS Work\\repo\\Pytorch LLM\\GPT4LanguageLearning\\main\\translation.py:233: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word Rarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>地图</td>\n",
       "      <td>Common</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>晚点</td>\n",
       "      <td>Common</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>起飞</td>\n",
       "      <td>Common</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>降落</td>\n",
       "      <td>Common</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word Word Rarity\n",
       "1   地图      Common\n",
       "2   晚点      Common\n",
       "3   起飞      Common\n",
       "4   降落      Common"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_response_translation = (\n",
    "    get_completion(\n",
    "        prompt=get_prompt_for_rarity_classification(word_list), model=\"gpt-4o-mini\" , temperature=temp))\n",
    "content = sample_response_translation.choices[0].message.content\n",
    "\n",
    "word_rarity_df = parse_translation_response(content)\n",
    "word_rarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite mode enabled.  Replacing 0 words and 4 new words added.\n"
     ]
    }
   ],
   "source": [
    "save_new_words_to_dict(\n",
    "    newwords_df = newwords_df.merge(word_rarity_df, on='Word', how='left'),\n",
    "    gsheet_mode= True,\n",
    "    overwrite_mode = True,\n",
    "    gsheet_name = gsheet_name,\n",
    "    worksheet_name = dict_sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dict(gsheet_mode=True, gsheet_name=gsheet_name, worksheet_name=dict_sheet_name)\n",
    "word_list = df['Word'].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [01:36<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_dfs = []\n",
    "max_retries = 3  # Set the number of retries per item\n",
    "attempt = 0\n",
    "batch_size = 5 \n",
    "\n",
    "for i in tqdm(range(0, len(word_list), batch_size)):\n",
    "    if attempt >= max_retries:\n",
    "        break\n",
    "    attempt = 0  # Reset the attempt counter if the operation succeeds\n",
    "    for _ in range(max_retries):\n",
    "        attempt += 1\n",
    "        try:\n",
    "            chunk = word_list[i:i+batch_size]\n",
    "            rarity_prompt = get_prompt_for_rarity_classification(chunk)\n",
    "            sample_response_translation = get_completion( prompt=rarity_prompt, model=\"gpt-4o-mini\" , temperature=temp)\n",
    "            content = sample_response_translation.choices[0].message.content\n",
    "            word_rarity_df = parse_translation_response(content)\n",
    "            all_dfs.append(word_rarity_df) \n",
    "            break  # If the task succeeds, move on to the next item\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt} failed for {chunk}: {e}\")\n",
    "            if attempt < max_retries :\n",
    "                time.sleep(1)  # Optional: Wait for 1 second before retrying\n",
    "            else:\n",
    "                print(f\"Exceed Maximum Retries for {chunk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Common    509\n",
       "Rare       27\n",
       "Name: Word Rarity, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.concat(all_dfs)\n",
    "df_result['Word Rarity'].value_counts()\n",
    "\n",
    "df_merge = df.merge(df_result.rename(columns={'Word Rarity': 'Rarity2'}), on='Word', how='left')\n",
    "df_merge['Word Rarity'] = np.where(df_merge['Word Rarity'] == \"\", df_merge['Rarity2'], df_merge['Word Rarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_df_to_gsheet(gsheet_name, dict_sheet_name, df_merge, overwrite_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Mentoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: <Insert **urs>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 112\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax attempts reached. Highest score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhighest_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Feedback from last attempt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedback_dict[attempt_count\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43minterpret_equality_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInterprete this \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEdge_PB_Share_Avg > 0.82\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnterpriseMobilityCoreE3Rev > 1907.40\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5921.00 < AADPAllUp_MAU <= 15701.50\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m to english\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[69], line 14\u001b[0m, in \u001b[0;36minterpret_equality_statement\u001b[1;34m(equality_statement)\u001b[0m\n\u001b[0;32m     10\u001b[0m feedback_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m attempt_count \u001b[38;5;241m<\u001b[39m max_attempts:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# MLS Simulation: Generate interpretation\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     interpretation \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mYou are a Machine Learning Scientist who converts equality statements into proper English.\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;43m                    An equality statement has the pattern \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<measure> <equality> <value>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m or \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<value> <equality> <measure> <equality> <value>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;43m                    <measure> has a mapping to proper English:\u001b[39;49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;43m                    Edge_PB_Share_Avg : Edge Primary Browser Share\u001b[39;49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;43m                    SPO_MAU : SharePoint Online MAU\u001b[39;49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;43m                    EnterpriseMobilityCoreE3Rev : EMS E3 Revenue\u001b[39;49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;43m                    AADPAllUp_MAU : Entra ID MAU\u001b[39;49m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;43m                    if <value> is less than 1, it is a percentage.\u001b[39;49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;43m                    if <value> is greater than 999, it must have comma(s).\u001b[39;49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;43m                    if <value> is greater than 1, it must be rounded to the nearest whole number.\u001b[39;49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;43m                    if <measure> has MAU, round <value> to the nearest hundred.\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;43m                    You always start an English sentence with the phrase \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWe recommend this product for this tenant because...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mequality_statement\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     generated_interpretation \u001b[38;5;241m=\u001b[39m interpretation\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Mentor Simulation: Generate mentor feedback\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wongs\\anaconda3\\lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wongs\\anaconda3\\lib\\site-packages\\openai\\resources\\chat\\completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wongs\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\wongs\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wongs\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    988\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <Insert **urs>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=\"<Insert yours>\")\n",
    "\n",
    "equality_statement = \"Interprete this 'Edge_PB_Share_Avg > 0.82', 'EnterpriseMobilityCoreE3Rev > 1907.40', '5921.00 < AADPAllUp_MAU <= 15701.50',\"\n",
    "\n",
    "def interpret_equality_statement(equality_statement):\n",
    "    # Initialize variables for tracking attempts\n",
    "    attempt_count = 0\n",
    "    max_attempts = 5\n",
    "    highest_score = 0\n",
    "    feedback_dict = {}\n",
    " \n",
    "    while attempt_count < max_attempts:\n",
    "        # MLS Simulation: Generate interpretation\n",
    "        interpretation = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a Machine Learning Scientist who converts equality statements into proper English.\n",
    "                        An equality statement has the pattern \"<measure> <equality> <value>\" or \"<value> <equality> <measure> <equality> <value>\".\n",
    "\n",
    "                        <measure> has a mapping to proper English:\n",
    "                        Edge_PB_Share_Avg : Edge Primary Browser Share\n",
    "                        SPO_MAU : SharePoint Online MAU\n",
    "                        EnterpriseMobilityCoreE3Rev : EMS E3 Revenue\n",
    "                        AADPAllUp_MAU : Entra ID MAU\n",
    "\n",
    "                        if <value> is less than 1, it is a percentage.\n",
    "                        if <value> is greater than 999, it must have comma(s).\n",
    "                        if <value> is greater than 1, it must be rounded to the nearest whole number.\n",
    "                        if <measure> has MAU, round <value> to the nearest hundred.\n",
    "\n",
    "                        You always start an English sentence with the phrase \"We recommend this product for this tenant because...\"\n",
    "\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": equality_statement\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        generated_interpretation = interpretation.choices[0].message.content\n",
    "\n",
    "        # Mentor Simulation: Generate mentor feedback\n",
    "        mentor_feedback = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a senior leader in an organization who evaluates the output of the Machine Learning Scientist. You will give them a score of their work from 1 to 10, and provide reasons and comments.\n",
    "\n",
    "                        Evaluation criteria:\n",
    "                        1. The equality statement should have the pattern \"<measure> <equality> <value>\" or \"<value> <equality> <measure> <equality> <value>\".\n",
    "                        2. The statement needs to be mapped to proper English:\n",
    "                            - Edge_PB_Share_Avg: Edge Primary Browser Share\n",
    "                            - SPO_MAU: SharePoint Online MAU\n",
    "                            - EnterpriseMobilityCoreE3Rev: EMS E3 Revenue\n",
    "                            - AADPAllUp_MAU: Entra ID MAU\n",
    "                        3. If <value> is less than 1, it's a percentage.\n",
    "                        4. If <value> is greater than 999, it should have commas.\n",
    "                        5. If <value> is greater than 1, round to the nearest whole number.\n",
    "                        6. If the <measure> has MAU, round the <value> to the nearest hundred.\n",
    "                        7. The English sentence should always start with the phrase \"We recommend this product for this tenant because...\".\n",
    "                        8. The response should be in professional English.\n",
    "                        9. Your mentee should not say the result is rounded or anything related to how they finish the process in the response, they should stick with the precise interpretation\n",
    "\n",
    "                        # Good Examples:\n",
    "                        Sharepoint Online usage is above 80%\n",
    "                        Azure Revenue is more than $1000\n",
    "                        the Entra ID MAU is between 5,900 and 15,700\n",
    "\n",
    "                        # Bad Examples:\n",
    "                        the Entrta ID MAU is between 5921 and 15701, rounded to the nearest hundred\n",
    "\n",
    "                     Sample output: Score: 8.5; Comments: This is good. You missed the SPO_MAU : SharePoint Online MAU converter\n",
    "                    This is just a sample output, you don't have to follow 100%, but think and give your feedback, if there is no mistake, you can give a 10 as well!\n",
    "                    But you need to strictly follow the sample output format with Score:<your score, one number or float>; Comments:< Your comments>  \n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Evaluate this work and provide a score and comment.\\nOriginal equality statement: {equality_statement}\\nWork: {generated_interpretation}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Parse mentor's feedback\n",
    "        mentor_response = mentor_feedback.choices[0].message.content\n",
    "        score = float(mentor_response.split('Score: ')[1].split(';')[0])\n",
    "        comment = mentor_response.split('Comments: ')[1]\n",
    " \n",
    "        # Check if the score is acceptable\n",
    "        if score >= 8.5:\n",
    "            return f\"Interpretation Approved: {generated_interpretation}\"\n",
    " \n",
    "        # If score is below 8.5, store the feedback\n",
    "        feedback_dict[attempt_count] = {'score': score, 'comment': comment}\n",
    "        highest_score = max(highest_score, score)\n",
    "\n",
    "        # Output feedback and ask user to revise with mentor's comment attached\n",
    "        print(f\"Attempt {attempt_count + 1}: Score: {score}, Feedback: {comment}\")\n",
    "        equality_statement = input(f\"Please revise your equality statement based on the mentor's feedback:\\n{comment}\\nYour revised statement: \")\n",
    "\n",
    "        attempt_count += 1\n",
    " \n",
    "    # If the loop ends without a passing score, output the highest score\n",
    "    return f\"Max attempts reached. Highest score: {highest_score}, Feedback from last attempt: {feedback_dict[attempt_count-1]['comment']}\"\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result = interpret_equality_statement(\"Interprete this 'Edge_PB_Share_Avg > 0.82', 'EnterpriseMobilityCoreE3Rev > 1907.40', '5921.00 < AADPAllUp_MAU <= 15701.50' to english\")\n",
    "print(result)\n",
    "\n",
    "             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
