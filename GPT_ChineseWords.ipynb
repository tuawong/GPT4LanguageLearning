{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Constants\n",
    "from  openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import gspread\n",
    "import gspread_dataframe as gd\n",
    "import gspread_formatting as gf\n",
    "from gspread_formatting import cellFormat, color, textFormat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample OpenAI Prompt Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = Constants.API_KEY_OPENAI,\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4o-mini\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Can you generate generate ten pairs of text between two to twenty words long each and label with emotion that most strongly associate with the text.   There are six possible emotions for labeling (\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\").  Make sure there's roughly equal number of each emotion.   \n",
    "\n",
    "An example would look like this\n",
    "\n",
    "1) 'i didnt feel humiliated' = 'sadness'\n",
    " 2) 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake' = 'sadness'\n",
    " 3)  'im grabbing a minute to post i feel greedy wrong' = 'anger'\n",
    " 4) 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property' = 'love'\n",
    " 5)  'i am feeling grouchy' = 'anger'\n",
    "\n",
    " Can you generate fifty pairs?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response_high_temp = get_completion(prompt=prompt, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are ten pairs labeled with their associated emotions. Each pair addresses distinct characteristics of the emotional spectrum you've provided. Here they range in words from two to twenty:\n",
      "\n",
      "1) \"I lost something I cherished.\" = 'sadness'\n",
      "2) \"Nothing beats the feeling of warm sunshine.\" = 'joy'\n",
      "3) \"I would do anything to keep you safe.\" = 'love'\n",
      "4) \"It's infuriating to see you waste your talent!\" = 'anger'\n",
      "5) \"I can't handle the uncertainty anymore.\" = 'fear'\n",
      "6) \"Surprisingly, everything turned out better than expected!\" = 'surprise'\n",
      "7) \"Remembering how lonely I felt last year.\" = 'sadness'\n",
      "8) \"There's so much to celebrate this weekend!\" = 'joy'\n",
      "9) \"Your compassion warms my heart softly.\" = 'love'\n",
      "10) \"It's hard not to explode with frustration.\" = 'anger'\n",
      "\n",
      "11) \"My heart scares me sometimes.\" = 'fear'\n",
      "12) \"I was shocked to see her at the event.\" = 'surprise'\n",
      "13) \"A farewell also means closure— I wish we had more time.\" = 'sadness'\n",
      "14) \"Laughing with friends fuels my spirit!\" = 'joy'\n",
      "15) \"There’s nothing I wouldn’t sacrifice to feel free.\" = 'love'\n",
      "16) \"You treat people so disrespectfully; it's disgusting!\" = 'anger'\n",
      "17) \"In the dark, all horrors seem possible.\" = 'fear'\n",
      "18) \"I never saw that plot twist coming!\" = 'surprise'\n",
      "19) \"The empty room echoes my sentiments.\" = 'sadness'\n",
      "20) \"Sharing moments brings me pure bliss.\" = 'joy'\n",
      "\n",
      "21) \"You complete me in every way.\" = 'love'\n",
      "22) \"It's maddening when plans just fall apart!\" = 'anger'\n",
      "23) \"Alien thoughts grip my chest at night.\" = 'fear'\n",
      "24) \"The sudden end was very shocking.\" = 'surprise'\n",
      "25) \"Tears remind me of how deeply I cared.\" = 'sadness'\n",
      "26) \"Every season change paints joy in my heart.\" = 'joy'\n",
      "27) \"Let's build our lives together.\" = 'love'\n",
      "28) \"I can’t stand how they overlooked my hard work!\" = 'anger'\n",
      "29) \"The shadows whisper unknown fears.\" = 'fear'\n",
      "30) \"Her winning smile caught everyone’s eye!\" = 'surprise'\n",
      "\n",
      "31) \"Grieving an old friend leaves an empty pit in my stomach.\" = 'sadness'\n",
      "32) \"Discovering hidden meanings always makes me smile.\" = 'joy'\n",
      "33) \"There is nothing but peace when we're together.\" = 'love'\n",
      "34) \"How dare you challenge my authority?!\" = 'anger'\n",
      "35) \"In that silence, I felt overwhelming dread.\" = 'fear'\n",
      "36) \"Finding a long-lost letter left me speechless.\" = 'surprise'\n",
      "37) \"Missing out on special moments felt heartbreaking.\" = 'sadness'\n",
      "38) \"Hiking gives me such joy; nothing compares.\" = 'joy'\n",
      "39) \"We're in this together, no matter the distance.\" = 'love'\n",
      "40) \"The constant noises made my head spin with irritation!\" = 'anger'\n",
      "\n",
      "41) \"Lost in thoughts that terrify me at night.\" = 'fear'\n",
      "42) \"His unexpected gift left me amazed.\" = 'surprise'\n",
      "43) \"Standing by the gravesite was haunting.\" = 'sadness'\n",
      "44) \"Nothing feels as light and beautiful as music.\" = 'joy'\n",
      "45) \"Each bubble bath feels like endless tranquility rekindled.\" = 'love'\n",
      "46) \"Clearing my plate can sometimes drive me mad!\" = 'anger'\n",
      "47) \"My ending performance didn’t go as planned; I wasn’t ready.\" = 'fear'\n",
      "48) \"Her smile lit up the dreariest room.\" = 'surprise'\n",
      "49) \"Carrying burdens that others cannot see distances me from joy.\" = 'sadness'\n",
      "50) \"Winning the award reshaped how I viewed myself.\" = 'joy' \n",
      "\n",
      "Feel free to then utilize, customize, or adjust these as fits your project or objectives!\n"
     ]
    }
   ],
   "source": [
    "print(sample_response_high_temp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = get_completion(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are fifty pairs of text labeled with the associated emotions:\n",
      "\n",
      "1) 'I can't believe they left me behind' = 'sadness'  \n",
      "2) 'The sun is shining, and I feel alive!' = 'joy'  \n",
      "3) 'I never knew love could feel this deep' = 'love'  \n",
      "4) 'Why did you betray my trust?' = 'anger'  \n",
      "5) 'I can't shake this feeling of dread' = 'fear'  \n",
      "\n",
      "6) 'I miss the days when we were together' = 'sadness'  \n",
      "7) 'Every moment with you is a treasure' = 'love'  \n",
      "8) 'I just won the lottery!' = 'joy'  \n",
      "9) 'How could you say that to me?' = 'anger'  \n",
      "10) 'What if I fail this time?' = 'fear'  \n",
      "\n",
      "11) 'I feel so alone in this crowded room' = 'sadness'  \n",
      "12) 'Your smile brightens my day' = 'joy'  \n",
      "13) 'I cherish every memory we made' = 'love'  \n",
      "14) 'This is completely unacceptable!' = 'anger'  \n",
      "15) 'I heard a strange noise outside' = 'fear'  \n",
      "\n",
      "16) 'I can't believe it's over' = 'sadness'  \n",
      "17) 'Today was the best day ever!' = 'joy'  \n",
      "18) 'You mean the world to me' = 'love'  \n",
      "19) 'I can't stand how they treated you' = 'anger'  \n",
      "20) 'What if they don't like me?' = 'fear'  \n",
      "\n",
      "21) 'I feel like I've lost a part of myself' = 'sadness'  \n",
      "22) 'I danced like nobody was watching!' = 'joy'  \n",
      "23) 'You have my heart forever' = 'love'  \n",
      "24) 'I can't believe you did that!' = 'anger'  \n",
      "25) 'I saw a shadow move in the dark' = 'fear'  \n",
      "\n",
      "26) 'The memories haunt me at night' = 'sadness'  \n",
      "27) 'I feel so grateful for my friends' = 'joy'  \n",
      "28) 'Your kindness warms my heart' = 'love'  \n",
      "29) 'This is infuriating!' = 'anger'  \n",
      "30) 'What if I never find my way back?' = 'fear'  \n",
      "\n",
      "31) 'I wish things could go back to how they were' = 'sadness'  \n",
      "32) 'I can't stop smiling!' = 'joy'  \n",
      "33) 'You are my everything' = 'love'  \n",
      "34) 'I can't believe you would lie to me!' = 'anger'  \n",
      "35) 'I feel like something bad is going to happen' = 'fear'  \n",
      "\n",
      "36) 'I feel empty without you' = 'sadness'  \n",
      "37) 'I just got a promotion!' = 'joy'  \n",
      "38) 'You make my heart skip a beat' = 'love'  \n",
      "39) 'This is so frustrating!' = 'anger'  \n",
      "40) 'What if I never get another chance?' = 'fear'  \n",
      "\n",
      "41) 'I can't stop crying' = 'sadness'  \n",
      "42) 'I love the sound of laughter' = 'joy'  \n",
      "43) 'You are my safe haven' = 'love'  \n",
      "44) 'I can't believe they would do that!' = 'anger'  \n",
      "45) 'I feel like I'm being watched' = 'fear'  \n",
      "\n",
      "46) 'I feel like I've been forgotten' = 'sadness'  \n",
      "47) 'This cake is delicious!' = 'joy'  \n",
      "48) 'You are my soulmate' = 'love'  \n",
      "49) 'I can't take this anymore!' = 'anger'  \n",
      "50) 'What if I never find happiness again?' = 'fear'  \n",
      "\n",
      "This set includes an equal distribution of emotions across the pairs.\n"
     ]
    }
   ],
   "source": [
    "print(sample_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Google Sheet API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Words Num Rows: 99\n",
      "Sheet Words Num Columns: 8\n"
     ]
    }
   ],
   "source": [
    "# No need to provide path for service account.  Json file is in the default directory for gspread at %APPDATA%/gspread/service_account.json\n",
    "sa = gspread.service_account()\n",
    "sh = sa.open(\"New Chinese Words\")\n",
    "\n",
    "sheet_name = \"Words\"\n",
    "wks2 = sh.worksheet(sheet_name)\n",
    "print(f'Sheet {sheet_name} Num Rows: {wks2.row_count}')\n",
    "print(f'Sheet {sheet_name} Num Columns: {wks2.col_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Type</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence Pinyin</th>\n",
       "      <th>Sentence Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>大概</td>\n",
       "      <td>da4 gai4</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>Approximately</td>\n",
       "      <td>他大概已经出发了</td>\n",
       "      <td>Tā dàgài yǐjīng chūfā le.</td>\n",
       "      <td>He probably already left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>被</td>\n",
       "      <td>bei4</td>\n",
       "      <td>Particle</td>\n",
       "      <td>Particle word to turn into passive voice.  (.i...</td>\n",
       "      <td>甜甜圈被吃掉了</td>\n",
       "      <td>tian2 tian2 quan1 bei4 chi1 diao4 le</td>\n",
       "      <td>The donut was eaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>往前</td>\n",
       "      <td>wang3 qian2</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>Go forward</td>\n",
       "      <td>往前走</td>\n",
       "      <td>wang3 qian2 zou3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>觉得</td>\n",
       "      <td>jue2 de</td>\n",
       "      <td>Verb</td>\n",
       "      <td>Think</td>\n",
       "      <td>你觉得她怎么样</td>\n",
       "      <td>ni3 jue2 de ta1 zen3 me yang</td>\n",
       "      <td>What do you think about her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>已经</td>\n",
       "      <td>yi3 jing1</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>Already</td>\n",
       "      <td>我已经吃过晚饭了</td>\n",
       "      <td>Wǒ yǐjīng chī guò wǎnfàn le.</td>\n",
       "      <td>I have already had dinner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 Word       Pinyin       Type  \\\n",
       "1   大概     da4 gai4  Adjective   \n",
       "2    被         bei4   Particle   \n",
       "3   往前  wang3 qian2  Adjective   \n",
       "4   觉得      jue2 de       Verb   \n",
       "5   已经    yi3 jing1     Adverb   \n",
       "\n",
       "0                                            Meaning  Sentence  \\\n",
       "1                                      Approximately  他大概已经出发了   \n",
       "2  Particle word to turn into passive voice.  (.i...   甜甜圈被吃掉了   \n",
       "3                                        Go forward        往前走   \n",
       "4                                              Think   你觉得她怎么样   \n",
       "5                                            Already  我已经吃过晚饭了   \n",
       "\n",
       "0                       Sentence Pinyin             Sentence Meaning  \n",
       "1             Tā dàgài yǐjīng chūfā le.     He probably already left  \n",
       "2  tian2 tian2 quan1 bei4 chi1 diao4 le          The donut was eaten  \n",
       "3                      wang3 qian2 zou3                               \n",
       "4          ni3 jue2 de ta1 zen3 me yang  What do you think about her  \n",
       "5          Wǒ yǐjīng chī guò wǎnfàn le.    I have already had dinner  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data = pd.DataFrame(wks2.get_all_values())\n",
    "current_data.columns = current_data.iloc[0]\n",
    "current_data = current_data.iloc[1:]\n",
    "current_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese Language Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.7\n",
    "overwrite_mode = False\n",
    "\n",
    "dict_path = \"ChineseWords/ChineseWordList.csv\"\n",
    "dict_sheet_name = \"AutoWordList\"\n",
    "gsheet_name = \"New Chinese Words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(\n",
    "        dict_path: str = None, \n",
    "        gsheet_mode=False, \n",
    "        gsheet_name = None, \n",
    "        worksheet_name = None\n",
    "        ):\n",
    "    if gsheet_mode:\n",
    "        sa = gspread.service_account()\n",
    "        sh = sa.open(gsheet_name)\n",
    "        wks = sh.worksheet(worksheet_name)\n",
    "        current_data = pd.DataFrame(wks.get_all_values())\n",
    "        current_data.columns = current_data.iloc[0]\n",
    "        current_data = current_data.iloc[1:]\n",
    "        return current_data\n",
    "    \n",
    "    else:\n",
    "        if os.path.exists(dict_path):\n",
    "            return pd.read_csv(dict_path)\n",
    "        else:\n",
    "            return pd.DataFrame(columns=[\"Chinese\", \"English\", \"Pinyin\"])\n",
    "\n",
    "     \n",
    "def save_df_to_gsheet(\n",
    "        gsheet_name, \n",
    "        wks_name,\n",
    "        df_to_save,\n",
    "        overwrite_mode = False\n",
    "    ):\n",
    "    sa = gspread.service_account()\n",
    "    sh = sa.open(gsheet_name)\n",
    "    wks = sh.worksheet(wks_name)\n",
    "\n",
    "    if not overwrite_mode:\n",
    "        existing = gd.get_as_dataframe(wks)\n",
    "        df_to_save = pd.concat([existing, df_to_save])\n",
    "    \n",
    "    gd.set_with_dataframe(wks, df_to_save)\n",
    "\n",
    "\n",
    "def format_gsheet(\n",
    "        gsheet_name, \n",
    "        wks_name\n",
    "    ):\n",
    "    sa = gspread.service_account()\n",
    "    sh = sa.open(gsheet_name)\n",
    "    wks = sh.wks(wks_name)\n",
    "\n",
    "    fmt = cellFormat(\n",
    "        backgroundColor=color(0.6, 0.8, 0.9),\n",
    "        textFormat=textFormat(bold=True, fontSize=15, foregroundColor=color(0, 0, 0.6)),\n",
    "        horizontalAlignment='CENTER'\n",
    "        )\n",
    "\n",
    "    gf.format_cell_range(wks, 'A1:H1', fmt)\n",
    "\n",
    "    fmt = cellFormat(\n",
    "        textFormat=textFormat(fontSize=15),\n",
    "        )\n",
    "\n",
    "    gf.format_cell_range(wks, 'A2:A500', fmt)\n",
    "    gf.format_cell_range(wks, 'E2:E500', fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat = pd.DataFrame(sa.open(\"New Chinese Words\").worksheet(dict_sheet_name).get_all_records())['Word Category'].unique()\n",
    "cat = ['General', 'Grammar', 'Direction', 'Opinion', 'Time',\n",
    "       'Description', 'Organization', 'Travel', 'Social', 'Technology',\n",
    "       'Health', 'Object', 'Work', 'Intent', 'Geography', 'Agriculture',\n",
    "       'Weather', 'Action', 'Problem Solving', 'Necessity', 'Support',\n",
    "       'Business', 'Information', 'Emotion', 'Assurance', 'Economics',\n",
    "       'Degree', 'Frequency', 'Question', 'Location', 'Sequence',\n",
    "       'Contrast', 'Thought', 'Relationship']\n",
    "\n",
    "def get_prompt_for_chinese_translation(chinese_words, existing_categories=cat):\n",
    "    chinese_prompt =  f\"\"\"\n",
    "    For each of the input Chinese words, please output the following as a one row in a table.  There should be the following columns in table related to the word.  \n",
    "\n",
    "    Generate output similar to the following example: \n",
    "    1. Word:  农场\n",
    "    2. Pinyin:  nong2 chang3\n",
    "    3. Type:   Noun (This should be adjusted whether the meaning of the word is noun/adjective/verb based on the meaning and example sentence)\n",
    "    4. Meaning:  Farm (This is could be a longer description of the meaning of the word if no exact translation exists in English)\n",
    "    5. Sentence:  我暑假打算去爷爷的农场帮忙  \n",
    "    6. Sentence Pinyin:  Wǒ shǔjià dǎsuàn qù yéye de nóngchǎng bāngmáng. \n",
    "    7. Sentence Meaning:  I plan to go to my grandfather's farm to help during the summer vacation.\n",
    "    8. Word Category: Agriculture (This should be a general category that the word belongs to)\n",
    "\n",
    "    For each word with multiple meanings, add more rows to the the table with alternate meaning and example sentence.  Each row should have a unique meaning.\n",
    "    If there is only one meaning, then keep only one row for each word.  Do not add rows for alternate meanings if there is only one meaning.  If the two meanings are sufficiently similar then they can be included in the same row.\n",
    "    If the meanings are different, then the second meaning should be in a new row with the same word, pinyin, word type, and sentence.  Don't omit any values in any row even if they are the same as the row above.\n",
    "    \n",
    "    All input words should be included in one table.  Only return the table with no other text.\n",
    "\n",
    "    Input Chinese Word = {chinese_words}\n",
    "    Do not include any word that is not in the list {chinese_words} in the Word column of the ouput table\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if existing_categories:\n",
    "        chinese_prompt = f\"\"\"\n",
    "            {chinese_prompt}\n",
    "\n",
    "            Existing Categories: {','.join(existing_categories)}\"\n",
    "            The categories above already exist in the database.  Only add new category if the word does not fit into any of the existing categories.\n",
    "            \"\"\"\n",
    "\n",
    "    return chinese_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_table_response(content: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Parse the table response from OpenAI into a pandas DataFrame\n",
    "    '''\n",
    "    # Using StringIO to treat the text as a file-like object for pandas\n",
    "    data = StringIO(content)\n",
    "\n",
    "    # Read the table into a pandas DataFrame\n",
    "    df = pd.read_csv(data, delimiter='|',  engine='python')\n",
    "\n",
    "    # Cleaning the DataFrame by stripping leading/trailing whitespaces from column names and data\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df = df.loc[~df.Word.str.contains('--')]\n",
    "\n",
    "    col_to_keep = [col for col in df if 'Unnamed' not in col]\n",
    "    df = df[col_to_keep]\n",
    "    df['Word'] = df.Word.replace('', pd.NA).ffill()\n",
    "    df['Pinyin'] = df.Pinyin.replace('', pd.NA).ffill()\n",
    "    df['Type'] = df.Type.replace('', pd.NA).ffill()\n",
    "    df['Added Date'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_new_words_to_dict(\n",
    "        newwords_df : pd.DataFrame, \n",
    "        gsheet_mode = False, \n",
    "        gsheet_name = None, \n",
    "        worksheet_name = None,\n",
    "        dict_path: str = None, \n",
    "        overwrite_mode: bool =False\n",
    "        ) -> None:\n",
    "    '''\n",
    "    Add new words to the Chinese dictionary and save to disk. \n",
    "    If overwrite_mode is enabled, then the new words will replace any existing words in the dictionary.  \n",
    "    Otherwise, only new words will be added to the dictionary.\n",
    "    '''\n",
    "    new_words = newwords_df['Word'].drop_duplicates().values\n",
    "\n",
    "    if gsheet_mode:\n",
    "        chinese_dict = load_dict(gsheet_mode=gsheet_mode, gsheet_name=gsheet_name, worksheet_name=worksheet_name)\n",
    "    else:\n",
    "        chinese_dict = pd.read_csv(dict_path) \n",
    "        \n",
    "    existing_words = chinese_dict['Word'].drop_duplicates().values\n",
    "\n",
    "    starting_words_len = len(existing_words)\n",
    "    new_words_len = len(new_words)\n",
    "\n",
    "    if overwrite_mode:\n",
    "        chinese_dict = chinese_dict.loc[~chinese_dict.Word.isin(new_words)]\n",
    "        dedup_words_len = len(chinese_dict['Word'].drop_duplicates().values)\n",
    "        chinese_dict = pd.concat([chinese_dict, newwords_df])\n",
    "        \n",
    "        print(f\"Overwrite mode enabled.  Replacing {starting_words_len - dedup_words_len} words and {new_words_len - (starting_words_len - dedup_words_len)} new words added.\")\n",
    "\n",
    "    else: \n",
    "        newwords_df = newwords_df.loc[~newwords_df.Word.isin(existing_words)]\n",
    "        dedup_words_len = len(newwords_df['Word'].drop_duplicates().values)\n",
    "        chinese_dict = pd.concat([chinese_dict, newwords_df])\n",
    "        \n",
    "        print(f\"Overwrite mode disabled.  {new_words_len - dedup_words_len} exists in current dictionary, adding {dedup_words_len} words.\")\n",
    "\n",
    "    if gsheet_mode:\n",
    "        save_df_to_gsheet(gsheet_name, worksheet_name, chinese_dict, overwrite_mode=True)\n",
    "    else:\n",
    "        chinese_dict.to_csv(dict_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response_translation = get_completion(prompt=get_prompt_for_chinese_translation(\"沟通, 正在, 与, 原因, 面临, 竞争, 对手\"), temperature=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Word   | Pinyin      | Type   | Meaning                                                            | Sentence                                       | Sentence Pinyin                                   | Sentence Meaning                                           | Word Category  |\n",
      "|--------|-------------|--------|--------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------|-----------------------------------------------------------|----------------|\n",
      "| 太太   | tàitài     | Noun   | Mrs.; a term of respect for a married woman                        | 她是我的太太。                                 | Tā shì wǒ de tàitài.                              | She is my wife.                                          | Social         |\n",
      "| 关系   | guānxì     | Noun   | Relationship; connection between people or things                   | 他们之间有很好的关系。                       | Tāmen zhījiān yǒu hěn hǎo de guānxì.              | There is a good relationship between them.               | Relationship    |\n",
      "|        |             | Verb   | To relate; to concern                                              | 这个问题与我们的项目有关系。                 | Zhège wèntí yǔ wǒmen de xiàngmù yǒu guānxì.        | This issue relates to our project.                       | Relationship    |\n",
      "| 同事   | tóngshì    | Noun   | Colleague; a person who works with you                              | 我的同事非常友好。                           | Wǒ de tóngshì fēicháng yǒuhǎo.                      | My colleague is very friendly.                           | Work           |\n"
     ]
    }
   ],
   "source": [
    "content = sample_response_translation.choices[0].message.content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Type</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence Pinyin</th>\n",
       "      <th>Sentence Meaning</th>\n",
       "      <th>Word Category</th>\n",
       "      <th>Added Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>太太</td>\n",
       "      <td>tàitài</td>\n",
       "      <td>Noun</td>\n",
       "      <td>Mrs.; a term of respect for a married woman</td>\n",
       "      <td>她是我的太太。</td>\n",
       "      <td>Tā shì wǒ de tàitài.</td>\n",
       "      <td>She is my wife.</td>\n",
       "      <td>Social</td>\n",
       "      <td>2024-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>关系</td>\n",
       "      <td>guānxì</td>\n",
       "      <td>Noun</td>\n",
       "      <td>Relationship; connection between people or things</td>\n",
       "      <td>他们之间有很好的关系。</td>\n",
       "      <td>Tāmen zhījiān yǒu hěn hǎo de guānxì.</td>\n",
       "      <td>There is a good relationship between them.</td>\n",
       "      <td>Relationship</td>\n",
       "      <td>2024-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>关系</td>\n",
       "      <td>guānxì</td>\n",
       "      <td>Verb</td>\n",
       "      <td>To relate; to concern</td>\n",
       "      <td>这个问题与我们的项目有关系。</td>\n",
       "      <td>Zhège wèntí yǔ wǒmen de xiàngmù yǒu guānxì.</td>\n",
       "      <td>This issue relates to our project.</td>\n",
       "      <td>Relationship</td>\n",
       "      <td>2024-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>同事</td>\n",
       "      <td>tóngshì</td>\n",
       "      <td>Noun</td>\n",
       "      <td>Colleague; a person who works with you</td>\n",
       "      <td>我的同事非常友好。</td>\n",
       "      <td>Wǒ de tóngshì fēicháng yǒuhǎo.</td>\n",
       "      <td>My colleague is very friendly.</td>\n",
       "      <td>Work</td>\n",
       "      <td>2024-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word   Pinyin  Type                                            Meaning  \\\n",
       "1   太太   tàitài  Noun        Mrs.; a term of respect for a married woman   \n",
       "2   关系   guānxì  Noun  Relationship; connection between people or things   \n",
       "3   关系   guānxì  Verb                              To relate; to concern   \n",
       "4   同事  tóngshì  Noun             Colleague; a person who works with you   \n",
       "\n",
       "         Sentence                              Sentence Pinyin  \\\n",
       "1         她是我的太太。                         Tā shì wǒ de tàitài.   \n",
       "2     他们之间有很好的关系。         Tāmen zhījiān yǒu hěn hǎo de guānxì.   \n",
       "3  这个问题与我们的项目有关系。  Zhège wèntí yǔ wǒmen de xiàngmù yǒu guānxì.   \n",
       "4       我的同事非常友好。               Wǒ de tóngshì fēicháng yǒuhǎo.   \n",
       "\n",
       "                             Sentence Meaning Word Category  Added Date  \n",
       "1                             She is my wife.        Social  2024-09-22  \n",
       "2  There is a good relationship between them.  Relationship  2024-09-22  \n",
       "3          This issue relates to our project.  Relationship  2024-09-22  \n",
       "4              My colleague is very friendly.          Work  2024-09-22  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newwords_df = parse_table_response(content)\n",
    "new_words = newwords_df['Word'].drop_duplicates().values\n",
    "newwords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite mode enabled.  Replacing 0 words and 3 new words added.\n"
     ]
    }
   ],
   "source": [
    "save_new_words_to_dict(\n",
    "    newwords_df = newwords_df,\n",
    "    gsheet_mode= True,\n",
    "    overwrite_mode = True,\n",
    "    gsheet_name = gsheet_name,\n",
    "    worksheet_name = dict_sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandarin Word Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_generate_word_quiz(\n",
    "    word_dict: pd.DataFrame,\n",
    "    startfrom_date_filter: str = None,\n",
    "    category_filter: str = None\n",
    "    ) -> str:\n",
    "        \n",
    "    if startfrom_date_filter:\n",
    "        word_dict = word_dict.loc[word_dict['Added Date'] >= startfrom_date_filter]\n",
    "\n",
    "    if category_filter:\n",
    "            word_dict = word_dict.loc[word_dict['Word Category'] == category_filter]\n",
    "\n",
    "    word_list = word_dict['Word'].drop_duplicates().sample(10).values\n",
    "    prompt = f''' \n",
    "    Given this word list:\n",
    "    {word_list}\n",
    "\n",
    "    Can you create an Mandarin exercise where you choose 10 non-duplicated words and an example sentence using them.   \n",
    "    Leaving 2 blank columns where user can input the pinyin and the meaning in English.\n",
    "\n",
    "    The output should only be a 10x4 table with no other written text.  The table should have the following columns:\n",
    "    1) Word\n",
    "    2) Sentence\n",
    "    3) Pinyin (Leave blank)\n",
    "    4) Meaning (Leave blank)\n",
    "    '''\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# 4O Maybe Necessary to Evaluate Quiz.  Mini seems to be halluciating quite a bit. \n",
    "def get_prompt_evaluate_quiz(\n",
    "        pinyin, \n",
    "        meaning\n",
    "    ) -> str:\n",
    "    prompt = f'''\n",
    "    Here's the answer provided.  Please check them for correctness and mark any incorrect answer and provide the correct one. \n",
    "\n",
    "    Please add the answers to column 3 and 4 in the original table.  Add four more columns at the end with the following values:\n",
    "    Pinyin Correct (Column #5):  Just yes/no response of whether the pinyin is correct\n",
    "    Pinyin Explanation (Column #6):  Should contain the correct pinyin if the answer is incorrect.  Blank otherwise.\n",
    "    Meaning Correct (Column #7):  Just yes/no response of whether the meaning is correct\n",
    "    Meaning Explanation (Column #8):  Short explanation of why the answer is incorrect and provide correct answer.  Blank otherwise.\n",
    "\n",
    "    The tone for the pinyin will be provided with number 1, 2, 3, 4, 5\n",
    "    The special character ü⁠ can be replaced by v in the answer\n",
    "\n",
    "    Pinyin: {pinyin}\n",
    "    Meaning: {meaning}\n",
    "\n",
    "    No other response should be given except the table\n",
    "    '''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = load_dict(gsheet_mode=True, gsheet_name=gsheet_name, worksheet_name=dict_sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_prompt = get_prompt_generate_word_quiz(\n",
    "    word_dict=word_dict,\n",
    "    startfrom_date_filter='2024-09-22',\n",
    ")\n",
    "\n",
    "sample_response_translation = get_completion(prompt=quiz_prompt, temperature=temp)\n",
    "\n",
    "content = sample_response_translation.choices[0].message.content\n",
    "data = StringIO(content)\n",
    "\n",
    "# Read the table into a pandas DataFrame\n",
    "df = pd.read_csv(data, delimiter='|',  engine='python')\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "col_to_keep = [col for col in df if 'Unnamed' not in col]\n",
    "df = df[col_to_keep]\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.loc[~df.Word.str.contains('--')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>糊涂</td>\n",
       "      <td>他在这个问题上很糊涂，不知道该怎么选择。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>决定</td>\n",
       "      <td>她终于决定去旅行，放松一下自己。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>误会</td>\n",
       "      <td>我们之间产生了误会，需要好好沟通。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>并</td>\n",
       "      <td>我们并不需要同时完成所有的任务。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>敌人</td>\n",
       "      <td>在比赛中，敌人是我们必须克服的挑战。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>讨论</td>\n",
       "      <td>我们可以在会议上讨论这个提议。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>认真</td>\n",
       "      <td>他对学习非常认真，总是提前完成作业。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>建议</td>\n",
       "      <td>我建议你多读书，丰富自己的知识。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>其实</td>\n",
       "      <td>其实这件事并没有那么复杂。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>答案</td>\n",
       "      <td>他的答案是正确的，得到了老师的表扬。</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word              Sentence Pinyin Meaning\n",
       "1    糊涂  他在这个问题上很糊涂，不知道该怎么选择。               \n",
       "2    决定      她终于决定去旅行，放松一下自己。               \n",
       "3    误会     我们之间产生了误会，需要好好沟通。               \n",
       "4     并      我们并不需要同时完成所有的任务。               \n",
       "5    敌人    在比赛中，敌人是我们必须克服的挑战。               \n",
       "6    讨论       我们可以在会议上讨论这个提议。               \n",
       "7    认真    他对学习非常认真，总是提前完成作业。               \n",
       "8    建议      我建议你多读书，丰富自己的知识。               \n",
       "9    其实         其实这件事并没有那么复杂。               \n",
       "10   答案    他的答案是正确的，得到了老师的表扬。               "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Mentoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<Insert yours>\")\n",
    "\n",
    "equality_statement = \"Interprete this 'Edge_PB_Share_Avg > 0.82', 'EnterpriseMobilityCoreE3Rev > 1907.40', '5921.00 < AADPAllUp_MAU <= 15701.50',\"\n",
    "\n",
    "def interpret_equality_statement(equality_statement):\n",
    "    # Initialize variables for tracking attempts\n",
    "    attempt_count = 0\n",
    "    max_attempts = 5\n",
    "    highest_score = 0\n",
    "    feedback_dict = {}\n",
    " \n",
    "    while attempt_count < max_attempts:\n",
    "        # MLS Simulation: Generate interpretation\n",
    "        interpretation = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a Machine Learning Scientist who converts equality statements into proper English.\n",
    "                        An equality statement has the pattern \"<measure> <equality> <value>\" or \"<value> <equality> <measure> <equality> <value>\".\n",
    "\n",
    "                        <measure> has a mapping to proper English:\n",
    "                        Edge_PB_Share_Avg : Edge Primary Browser Share\n",
    "                        SPO_MAU : SharePoint Online MAU\n",
    "                        EnterpriseMobilityCoreE3Rev : EMS E3 Revenue\n",
    "                        AADPAllUp_MAU : Entra ID MAU\n",
    "\n",
    "                        if <value> is less than 1, it is a percentage.\n",
    "                        if <value> is greater than 999, it must have comma(s).\n",
    "                        if <value> is greater than 1, it must be rounded to the nearest whole number.\n",
    "                        if <measure> has MAU, round <value> to the nearest hundred.\n",
    "\n",
    "                        You always start an English sentence with the phrase \"We recommend this product for this tenant because...\"\n",
    "\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": equality_statement\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        generated_interpretation = interpretation.choices[0].message.content\n",
    "\n",
    "        # Mentor Simulation: Generate mentor feedback\n",
    "        mentor_feedback = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a senior leader in an organization who evaluates the output of the Machine Learning Scientist. You will give them a score of their work from 1 to 10, and provide reasons and comments.\n",
    "\n",
    "                        Evaluation criteria:\n",
    "                        1. The equality statement should have the pattern \"<measure> <equality> <value>\" or \"<value> <equality> <measure> <equality> <value>\".\n",
    "                        2. The statement needs to be mapped to proper English:\n",
    "                            - Edge_PB_Share_Avg: Edge Primary Browser Share\n",
    "                            - SPO_MAU: SharePoint Online MAU\n",
    "                            - EnterpriseMobilityCoreE3Rev: EMS E3 Revenue\n",
    "                            - AADPAllUp_MAU: Entra ID MAU\n",
    "                        3. If <value> is less than 1, it's a percentage.\n",
    "                        4. If <value> is greater than 999, it should have commas.\n",
    "                        5. If <value> is greater than 1, round to the nearest whole number.\n",
    "                        6. If the <measure> has MAU, round the <value> to the nearest hundred.\n",
    "                        7. The English sentence should always start with the phrase \"We recommend this product for this tenant because...\".\n",
    "                        8. The response should be in professional English.\n",
    "                        9. Your mentee should not say the result is rounded or anything related to how they finish the process in the response, they should stick with the precise interpretation\n",
    "\n",
    "                        # Good Examples:\n",
    "                        Sharepoint Online usage is above 80%\n",
    "                        Azure Revenue is more than $1000\n",
    "                        the Entra ID MAU is between 5,900 and 15,700\n",
    "\n",
    "                        # Bad Examples:\n",
    "                        the Entrta ID MAU is between 5921 and 15701, rounded to the nearest hundred\n",
    "\n",
    "                     Sample output: Score: 8.5; Comments: This is good. You missed the SPO_MAU : SharePoint Online MAU converter\n",
    "                    This is just a sample output, you don't have to follow 100%, but think and give your feedback, if there is no mistake, you can give a 10 as well!\n",
    "                    But you need to strictly follow the sample output format with Score:<your score, one number or float>; Comments:< Your comments>  \n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Evaluate this work and provide a score and comment.\\nOriginal equality statement: {equality_statement}\\nWork: {generated_interpretation}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Parse mentor's feedback\n",
    "        mentor_response = mentor_feedback.choices[0].message.content\n",
    "        score = float(mentor_response.split('Score: ')[1].split(';')[0])\n",
    "        comment = mentor_response.split('Comments: ')[1]\n",
    " \n",
    "        # Check if the score is acceptable\n",
    "        if score >= 8.5:\n",
    "            return f\"Interpretation Approved: {generated_interpretation}\"\n",
    " \n",
    "        # If score is below 8.5, store the feedback\n",
    "        feedback_dict[attempt_count] = {'score': score, 'comment': comment}\n",
    "        highest_score = max(highest_score, score)\n",
    "\n",
    "        # Output feedback and ask user to revise with mentor's comment attached\n",
    "        print(f\"Attempt {attempt_count + 1}: Score: {score}, Feedback: {comment}\")\n",
    "        equality_statement = input(f\"Please revise your equality statement based on the mentor's feedback:\\n{comment}\\nYour revised statement: \")\n",
    "\n",
    "        attempt_count += 1\n",
    " \n",
    "    # If the loop ends without a passing score, output the highest score\n",
    "    return f\"Max attempts reached. Highest score: {highest_score}, Feedback from last attempt: {feedback_dict[attempt_count-1]['comment']}\"\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result = interpret_equality_statement(\"Interprete this 'Edge_PB_Share_Avg > 0.82', 'EnterpriseMobilityCoreE3Rev > 1907.40', '5921.00 < AADPAllUp_MAU <= 15701.50' to english\")\n",
    "print(result)\n",
    "\n",
    "             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
